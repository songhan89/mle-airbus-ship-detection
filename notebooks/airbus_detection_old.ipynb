{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dbc043-e609-4d73-9f68-c01625d41bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ea4cad8942bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# from tfx.proto import example_gen_pb2, transform_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# from tensorflow_metadata.proto.v0 import schema_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrle_decode_tf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import gc; gc.enable() # memory is tight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage\n",
    "from typing import List\n",
    "from google.cloud import bigquery, storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from absl import logging\n",
    "\n",
    "from src.utils.common import rle_decode_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a15498-9360-4d7f-98da-993d6bcaa01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U tfx\n",
    "#!pip install python-snappy\n",
    "#!pip install apache-beam[interactive]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae24734-01cb-4e7c-a8ab-37615a41223c",
   "metadata": {},
   "source": [
    "## TODO: To convert below to Argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6ede85-ab8b-43d1-85b6-05cb9c4996d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT: gs://mle_airbus_dataset/airbusmlepipeline/pipeline_root\n",
      "MODULE_ROOT: gs://mle_airbus_dataset/airbusmlepipeline/pipeline_module\n",
      "DATA_ROOT: gs://mle_airbus_dataset/airbusmlepipeline/data\n",
      "SERVING_MODEL_DIR: gs://mle_airbus_dataset/airbusmlepipeline/serving_model\n",
      "Project ID: mle-airbus-detection-smu\n",
      "Region: asia-east1\n",
      "Bucket name: mle_airbus_dataset\n",
      "Service Account: service-account-for-mle@mle-airbus-detection-smu.iam.gserviceaccount.com\n",
      "Vertex API Parent URI: projects/mle-airbus-detection-smu/locations/asia-east1\n",
      "gs://mle_airbus_dataset/train_v2/\n",
      "                                 gs://mle_airbus_dataset/train_v2/\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'mle-airbus-detection-smu' # Change to your project id.\n",
    "PROJECT_NUMBER = '484894607141'\n",
    "REGION = 'asia-east1' # Change to your region.\n",
    "BUCKET = 'mle_airbus_dataset' # Change to your bucket name.\n",
    "SERVICE_ACCOUNT = \"service-account-for-mle@mle-airbus-detection-smu.iam.gserviceaccount.com\"\n",
    "\n",
    "if PROJECT == \"\" or PROJECT is None or PROJECT == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT = shell_output[0]\n",
    "    \n",
    "if SERVICE_ACCOUNT == \"\" or SERVICE_ACCOUNT is None or SERVICE_ACCOUNT == \"[your-service-account]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.account)' 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"[your-bucket-name]\":\n",
    "    # Get your bucket name to GCP projet id\n",
    "    BUCKET = PROJECT\n",
    "    # Try to create the bucket if it doesn'exists\n",
    "    ! gsutil mb -l $REGION gs://$BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "PARENT = f\"projects/{PROJECT}/locations/{REGION}\"\n",
    "\n",
    "PIPELINE_NAME = 'airbusmlepipeline'\n",
    "\n",
    "# Path to various pipeline artifact.\n",
    "PIPELINE_ROOT = 'gs://{}/{}/pipeline_root'.format(\n",
    "    BUCKET, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' Python module.\n",
    "MODULE_ROOT = 'gs://{}/{}/pipeline_module'.format(\n",
    "    BUCKET, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' data.\n",
    "DATA_ROOT = 'gs://{}/{}/data'.format(BUCKET, PIPELINE_NAME)\n",
    "\n",
    "# This is the path where your model will be pushed for serving.\n",
    "SERVING_MODEL_DIR = 'gs://{}/{}/serving_model'.format(\n",
    "    BUCKET, PIPELINE_NAME)\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))\n",
    "print('MODULE_ROOT: {}'.format(MODULE_ROOT))\n",
    "print('DATA_ROOT: {}'.format(DATA_ROOT))\n",
    "print('SERVING_MODEL_DIR: {}'.format(SERVING_MODEL_DIR))\n",
    "\n",
    "BQ_DATASET_NAME = 'mle-airbus-detection-smu.airbus_label_dataset' # Change to your BQ dataset name.\n",
    "BQ_TABLE_NAME = 'airbus_label'\n",
    "BQ_LOCATION = ' asia-east1'\n",
    "    \n",
    "print(\"Project ID:\", PROJECT)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)\n",
    "print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "print(\"Vertex API Parent URI:\", PARENT)\n",
    "\n",
    "! gsutil ls -al \"gs://\"$BUCKET\n",
    "\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT)\n",
    "bucket = storage_client.get_bucket(BUCKET)\n",
    "storage_path = f\"gs://{BUCKET}/train_v2/\"\n",
    "print (storage_path)\n",
    "\n",
    "VERSION = 'v01'\n",
    "DATASET_DISPLAY_NAME = 'airbus-ship-dataset-display'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "\n",
    "WORKSPACE = f'gs://{BUCKET}/{DATASET_DISPLAY_NAME}'\n",
    "EXPERIMENT_ARTIFACTS_DIR = os.path.join(WORKSPACE, 'experiments')\n",
    "\n",
    "TENSORBOARD_DISPLAY_NAME = f'tb-{DATASET_DISPLAY_NAME}'\n",
    "EXPERIMENT_NAME = f'{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 5\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 400\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 200\n",
    "AUGMENT_BRIGHTNESS = False\n",
    "N_SAMPLE = 10\n",
    "IMG_SHAPE = (768, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8ba279-3f2b-4e28-95f2-e01923ffb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%bigquery` not found.\n"
     ]
    }
   ],
   "source": [
    "%%bigquery masks\n",
    "\n",
    "SELECT * FROM `mle-airbus-detection-smu.airbus_data.label_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bd417a-2ad4-4212-b230-d71f25907f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"SELECT * FROM `mle-airbus-detection-smu.airbus_data.label_data`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa208e56-7a17-47d6-9d25-a9ffee145048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>198320 10 199088 10 199856 10 200624 10 201392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "1  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "2  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...\n",
       "3  000194a2d.jpg  198320 10 199088 10 199856 10 200624 10 201392...\n",
       "4  000194a2d.jpg  55683 1 56451 1 57219 1 57987 1 58755 1 59523 ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef8aef-e23b-48f5-acdb-8444e9f4ba6a",
   "metadata": {},
   "source": [
    "# Experimental - TFX pipeline\n",
    "### Setup BigQuery Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1b8c858-5426-42af-9b70-e4e78c1922e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Component declared as a typehint-annotated function must have either an OutputDict instance or `None` as its return value typehint.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_512/2656678096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfx_pipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBigQueryReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m def BigQueryReader(\n\u001b[1;32m      4\u001b[0m     \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mParameter\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ):\n",
      "\u001b[0;32m~/src/tfx_pipelines/components.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mn_sample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mParameter\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mbalance\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mParameter\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   ) -> Parameter [bytes]:\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mbqclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tfx/dsl/component/experimental/decorators.py\u001b[0m in \u001b[0;36mcomponent\u001b[0;34m(func, component_annotation, use_beam)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m   inputs, outputs, parameters, arg_formats, arg_defaults, returned_values = (\n\u001b[0;32m--> 416\u001b[0;31m       function_parser.parse_typehint_component_function(func))\n\u001b[0m\u001b[1;32m    417\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_beam\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BeamPipeline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     raise ValueError('The decorated function must have one and only one '\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tfx/dsl/component/experimental/function_parser.py\u001b[0m in \u001b[0;36mparse_typehint_component_function\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    276\u001b[0m   \u001b[0margspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=module-attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0msubject_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Component declared as a typehint-annotated function'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m   \u001b[0m_validate_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypehints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0;31m# Parse the function and return its details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tfx/dsl/component/experimental/function_parser.py\u001b[0m in \u001b[0;36m_validate_signature\u001b[0;34m(func, argspec, typehints, subject_message)\u001b[0m\n\u001b[1;32m     99\u001b[0m     raise ValueError(\n\u001b[1;32m    100\u001b[0m         ('%s must have either an OutputDict instance or `None` as its return '\n\u001b[0;32m--> 101\u001b[0;31m          'value typehint.') % subject_message)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Component declared as a typehint-annotated function must have either an OutputDict instance or `None` as its return value typehint."
     ]
    }
   ],
   "source": [
    "from src.tfx_pipelines.components import BigQueryReader\n",
    "@component\n",
    "def BigQueryReader(\n",
    "    query: Parameter [str]\n",
    "    ):\n",
    "    bqclient = bigquery.Client()\n",
    "\n",
    "    dataframe = (\n",
    "        bqclient.query(query)\n",
    "        .result()\n",
    "        .to_dataframe(\n",
    "            # Optionally, explicitly request to use the BigQuery Storage API. As of\n",
    "            # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n",
    "            # API is used by default.\n",
    "            create_bqstorage_client=True,\n",
    "        )\n",
    "    )\n",
    "    print(dataframe.head())\n",
    "    logging(\"test\")\n",
    "\n",
    "    \n",
    "generator = BigQueryReader(query=QUERY)\n",
    "\n",
    "# from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "# context = InteractiveContext()\n",
    "# context.run(generator)\n",
    "# # @component\n",
    "# def MyTrainerComponent(\n",
    "#     training_data: tfx.dsl.components.InputArtifact[tfx.types.standard_artifacts.Examples],\n",
    "#     ) -> tfx.dsl.components.OutputDict(loss=object, accuracy=float):\n",
    "#     '''My simple trainer component.'''\n",
    "\n",
    "#     records = read_examples(training_data.uri)\n",
    "#     model_obj = train_model(records, num_iterations, dropout_hyperparameter)\n",
    "#     model_obj.write_to(model.uri)\n",
    "\n",
    "#     return {\n",
    "#     'loss': model_obj.loss,\n",
    "#     'accuracy': model_obj.accuracy\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19951af5-7bb2-4dd6-9c83-0925befeb28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "def _create_pipeline(\n",
    "    pipeline_name: str, \n",
    "    pipeline_root: str, \n",
    "    query: str,\n",
    "    module_file: str, \n",
    "    serving_model_dir: str,\n",
    "    beam_pipeline_args: Optional[List[str]]) -> tfx.v1.dsl.Pipeline:\n",
    "  \"\"\"Creates a TFX pipeline using BigQuery.\"\"\"\n",
    "\n",
    "  generator = BigQueryReader(query=QUERY)\n",
    "\n",
    "  components = [\n",
    "    generator\n",
    "  ]\n",
    "\n",
    "  return tfx.v1.dsl.Pipeline(\n",
    "    pipeline_name=pipeline_name,\n",
    "    pipeline_root=pipeline_root,\n",
    "    components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c89c3dfd-1761-4fd4-9341-ae6ebaecb07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob created. Resource name: projects/484894607141/locations/asia-east1/pipelineJobs/airbusmlepipeline-20220612024226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/484894607141/locations/asia-east1/pipelineJobs/airbusmlepipeline-20220612024226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_job = aiplatform.PipelineJob.get('projects/484894607141/locations/asia-east1/pipelineJobs/airbusmlepipeline-20220612024226')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/484894607141/locations/asia-east1/pipelineJobs/airbusmlepipeline-20220612024226')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-east1/pipelines/runs/airbusmlepipeline-20220612024226?project=484894607141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-east1/pipelines/runs/airbusmlepipeline-20220612024226?project=484894607141\n"
     ]
    }
   ],
   "source": [
    "# docs_infra: no_execute\n",
    "import os\n",
    "\n",
    "# We need to pass some GCP related configs to BigQuery. This is currently done\n",
    "# using `beam_pipeline_args` parameter.\n",
    "BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS = [\n",
    "   '--project=' + f\"'{PROJECT}'\",\n",
    "   '--temp_location=' + os.path.join('gs://', BUCKET, 'tmp')\n",
    "   ]\n",
    "\n",
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "\n",
    "runner = tfx.v1.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.v1.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        query=QUERY,\n",
    "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
    "        serving_model_dir=SERVING_MODEL_DIR,\n",
    "        beam_pipeline_args=BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS))\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "aiplatform.init(project=PROJECT, location=REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d3965048-e393-42b8-ace7-61b7d4488f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_trainer_module_file = 'penguin_trainer.py'\n",
    "\n",
    "context = InteractiveContext(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  metadata_connection_config=connection_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e81da5b2-c0ce-4a8f-85a7-68a60fc25e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OutputChannel(artifact_type=Examples, producer_component_id=BigQueryExampleGen, output_key=examples, additional_properties={}, additional_custom_properties={})\n"
     ]
    }
   ],
   "source": [
    "beam_pipeline_args=[\n",
    "    f\"--project={PROJECT}\",\n",
    "    f\"--temp_location={os.path.join(WORKSPACE, 'tmp')}\"\n",
    "]\n",
    "\n",
    "print (train_example_gen.outputs['examples'])\n",
    "# context.run(\n",
    "#     train_example_gen,\n",
    "#     beam_pipeline_args=beam_pipeline_args,\n",
    "#     enable_cache=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905c8c8e-530e-456f-8274-e3ccb0a2edaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfdv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1812/1943152321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_example_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'examples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Split-train/*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msource_raw_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfdv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_schema_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_SCHEMA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'schema.pbtxt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mraw_feature_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema_as_feature_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_raw_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_parse_tf_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfdv' is not defined"
     ]
    }
   ],
   "source": [
    "train_uri = os.path.join(train_example_gen.outputs['examples'].get()[0].uri, \"Split-train/*\")\n",
    "source_raw_schema = tfdv.load_schema_text(os.path.join(RAW_SCHEMA_DIR, 'schema.pbtxt'))\n",
    "raw_feature_spec = schema_utils.schema_as_feature_spec(source_raw_schema).feature_spec\n",
    "\n",
    "def _parse_tf_example(tfrecord):\n",
    "    return tf.io.parse_single_example(tfrecord, raw_feature_spec)\n",
    "\n",
    "tfrecord_filenames = tf.data.Dataset.list_files(train_uri)\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "dataset = dataset.map(_parse_tf_example)\n",
    "\n",
    "for raw_features in dataset.shuffle(1000).batch(3).take(1):\n",
    "    for key in raw_features:\n",
    "        print(f\"{key}: {np.squeeze(raw_features[key], -1)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb058ee3-9a7d-4858-b0a6-78e020fdfc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguin_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy,BinaryCrossentropy \n",
    "from src.models.u_net import UNet_keras\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) #- dice_coef(in_gt, in_pred)\n",
    "\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "\n",
    "\n",
    "_FEATURE_KEYS = [\n",
    "    'ImageId'\n",
    "]\n",
    "_LABEL_KEY = 'EncodedPixels'\n",
    "\n",
    "_TRAIN_BATCH_SIZE = 20\n",
    "_EVAL_BATCH_SIZE = 10\n",
    "\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.strings)\n",
    "           for feature in _FEATURE_KEYS\n",
    "       },\n",
    "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.strings)\n",
    "}\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: List of paths or patterns of input tfrecord files.\n",
    "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
    "    schema: schema of the input data.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "def _make_keras_model() -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
    "\n",
    "  Returns:\n",
    "    A Keras Model.\n",
    "  \"\"\"\n",
    "  # The model below is built with Functional API, please refer to\n",
    "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
    "\n",
    "    model = UNet_keras()\n",
    "\n",
    "    model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])\n",
    "    model.summary(print_fn=logging.info)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
    "  # version provided by pipeline author. A schema can also derived from TFT\n",
    "  # graph if a Transform component is used. In the case when either is missing,\n",
    "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
    "  # feature_spec, but the schema returned would be very primitive.\n",
    "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_TRAIN_BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "  model = _make_keras_model()\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      epochs=5,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "  # directory.\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2005f8-94f0-4f12-9ac8-6b4a35f65d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "# checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "#                              save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "# reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "#                                    patience=3, \n",
    "#                                    verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "# early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "#                       mode=\"max\", \n",
    "#                       patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "# callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "# step_count = min(MAX_TRAIN_STEPS, train_df_balanced.shape[0]//BATCH_SIZE)\n",
    "# loss_history = [seg_model.fit(dataset, \n",
    "#                              steps_per_epoch=step_count, \n",
    "#                              epochs=NB_EPOCHS, \n",
    "#                              validation_data=validation,\n",
    "#                              callbacks=callbacks_list,\n",
    "#                             workers=1 # the generator is not very thread safe\n",
    "#                                        )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1182884e-a4a9-48f8-a947-7dbd3c29f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, query: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     beam_pipeline_args: Optional[List[str]],\n",
    "                     ) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a TFX pipeline using BigQuery.\"\"\"\n",
    "\n",
    "  # NEW: Query data in BigQuery as a data source.\n",
    "  example_gen = tfx.extensions.google_cloud_big_query.BigQueryExampleGen(\n",
    "      query=query)\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
    "\n",
    "  # Pushes the model to a file destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  components = [\n",
    "      example_gen,\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=components,\n",
    "      # NEW: `beam_pipeline_args` is required to use BigQueryExampleGen.\n",
    "      beam_pipeline_args=beam_pipeline_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0d14f-b1c8-4a31-a08e-840e7552cf2c",
   "metadata": {},
   "source": [
    "## Working Pipeline in Python that has yet to be migrated to TFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2b6548-72b5-43e4-9929-5bb641c44848",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['EncodedPixels'].replace(np.nan, '0', inplace=True)\n",
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "# unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "masks.drop(['ships'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85817ba2-7a4b-43b3-b8d0-ec55affccc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148304 training masks\n",
      "46350 tests masks\n",
      "100 validation masks\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, test_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.2, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_ids, valid_ids = train_test_split(train_ids, \n",
    "                 test_size = 0.2, \n",
    "                 stratify = train_ids['ships']) \n",
    "train_df = pd.merge(masks, train_ids)\n",
    "test_df = pd.merge(masks, test_ids)\n",
    "valid_df = pd.merge(masks, valid_ids).sample(n=100)\n",
    "\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(test_df.shape[0], 'tests masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdd1f447-62fb-4325-b44c-072e5ff9a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rebalance label\n",
    "from sklearn.utils import resample\n",
    "#train_df['ships'].hist()\n",
    "\n",
    "train_df_balanced = pd.DataFrame()\n",
    "for ship_num in train_df['ships'].unique():\n",
    "    train_df_balanced = train_df_balanced.append(resample(train_df.query(\"ships == {}\".format(ship_num)), n_samples=N_SAMPLE))\n",
    "\n",
    "train_df_balanced.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1ca02ae-ab0c-4824-91eb-b54e2a277540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 2/2 [00:00<00:00, 985.85query/s]                         \n",
      "Downloading: 100%|██████████| 148304/148304 [00:02<00:00, 63342.77rows/s] \n"
     ]
    }
   ],
   "source": [
    "%%bigquery train_df\n",
    "\n",
    "SELECT * FROM `mle-airbus-detection-smu.airbus_label_dataset.train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24c6bdc-7e65-4c07-a2d8-45dcce9afd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import bigquery\n",
    "# import pandas_gbq as pd_gbq\n",
    "\n",
    "\n",
    "# # Construct a BigQuery client object.\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# # TODO: Set project_id to your Google Cloud Platform project ID.\n",
    "# project_id = \"mle-airbus-detection-smu\"\n",
    "\n",
    "# # TODO: Set table_id to the full destination table ID (including the\n",
    "# #       dataset ID).\n",
    "# train_table_id = 'airbus_label_dataset.train'\n",
    "# valid_table_id = 'airbus_label_dataset.valid'\n",
    "# test_table_id = 'airbus_label_dataset.test'\n",
    "\n",
    "# pd_gbq.to_gbq(train_df, train_table_id, project_id=project_id, if_exists='replace')\n",
    "# pd_gbq.to_gbq(valid_df, valid_table_id, project_id=project_id, if_exists='replace')\n",
    "# pd_gbq.to_gbq(test_df, test_table_id, project_id=project_id, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69944f4a-5a7f-486e-94ef-408fbfeefae7",
   "metadata": {},
   "source": [
    "## Dataloader Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17538997-3f56-483f-b8c0-54152d9f2b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7231c10ba.jpg</td>\n",
       "      <td>174423 35 175157 69 175925 69 176693 69 177461...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5d5d8a34.jpg</td>\n",
       "      <td>413185 3 413953 7 414721 12 415489 16 416257 2...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94e208d33.jpg</td>\n",
       "      <td>413538 6 414306 11 415074 11 415842 11 416610 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a5d5d8a34.jpg</td>\n",
       "      <td>413185 3 413953 7 414721 12 415489 16 416257 2...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>012d9c145.jpg</td>\n",
       "      <td>126923 2 127691 4 128458 7 129226 8 129993 9 1...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>15edd5fb8.jpg</td>\n",
       "      <td>178783 6 179551 11 180319 11 181087 11 181854 ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>e4ef760dd.jpg</td>\n",
       "      <td>416250 4 417018 7 417786 7 418553 8 419321 8 4...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3feaa0996.jpg</td>\n",
       "      <td>323942 1 324709 4 325477 5 326244 8 327011 11 ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>ed995c20f.jpg</td>\n",
       "      <td>339798 3 340566 7 341334 11 342101 13 342869 1...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5f3948811.jpg</td>\n",
       "      <td>24218 1 24985 3 25752 5 26519 8 27288 8 28057 ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ImageId                                      EncodedPixels  ships  \\\n",
       "0    7231c10ba.jpg  174423 35 175157 69 175925 69 176693 69 177461...      5   \n",
       "1    a5d5d8a34.jpg  413185 3 413953 7 414721 12 415489 16 416257 2...      5   \n",
       "2    94e208d33.jpg  413538 6 414306 11 415074 11 415842 11 416610 ...      5   \n",
       "3    a5d5d8a34.jpg  413185 3 413953 7 414721 12 415489 16 416257 2...      5   \n",
       "4    012d9c145.jpg  126923 2 127691 4 128458 7 129226 8 129993 9 1...      5   \n",
       "..             ...                                                ...    ...   \n",
       "145  15edd5fb8.jpg  178783 6 179551 11 180319 11 181087 11 181854 ...     14   \n",
       "146  e4ef760dd.jpg  416250 4 417018 7 417786 7 418553 8 419321 8 4...     14   \n",
       "147  3feaa0996.jpg  323942 1 324709 4 325477 5 326244 8 327011 11 ...     14   \n",
       "148  ed995c20f.jpg  339798 3 340566 7 341334 11 342101 13 342869 1...     14   \n",
       "149  5f3948811.jpg  24218 1 24985 3 25752 5 26519 8 27288 8 28057 ...     14   \n",
       "\n",
       "     has_ship  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "..        ...  \n",
       "145       1.0  \n",
       "146       1.0  \n",
       "147       1.0  \n",
       "148       1.0  \n",
       "149       1.0  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00762b2-ef98-4c65-b369-cf086bcf4a96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-192a14940bb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_db_to_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.utils.dataset import parse_db_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6774ed-9f9e-41fc-adf9-eb492350398c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.layers' has no attribute 'RandomRotation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-833482e5ac4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     [\n\u001b[0;32m      6\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomFlip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomRotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomHeight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomWidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'RandomRotation'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_reprocessing = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomHeight(0.1),\n",
    "        layers.RandomWidth(0.1),\n",
    "        layers.RandomZoom(0.9),\n",
    "        layers.Rescaling(1.0 / 255),\n",
    "        layers.Resizing(IMG_SHAPE[0], IMG_SHAPE[0])\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_df_balanced['ImageId'].values, train_df_balanced['EncodedPixels'].values))\n",
    "dataset = dataset.shuffle(buffer_size=1000)\n",
    "dataset = dataset.map(lambda x, y: parse_db_to_img(storage_path + x, y))\n",
    "dataset = dataset.map(lambda x, y: (x, y))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "validation = tf.data.Dataset.from_tensor_slices((valid_df['ImageId'].values, valid_df['EncodedPixels'].values))\n",
    "validation = validation.shuffle(buffer_size=10)\n",
    "validation = validation.map(parse_db_to_img)\n",
    "validation = validation.batch(BATCH_SIZE)\n",
    "validation = validation.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bec273-8c6d-47ed-a812-7fe667034e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "for images, labels in dataset.take(1):\n",
    "    images = images[0]\n",
    "    labels = labels[0]\n",
    "    ax[0] = ax[0].imshow(images)\n",
    "    ax[1] = ax[1].imshow(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a16dd6-e424-4741-855e-740ef9d062cd",
   "metadata": {},
   "source": [
    "## TODO: Clean up the code base and replace keras with TF for the U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24ea7a-4bb7-4959-b933-ede1ca77d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.u_net import UNet_keras\n",
    "seg_model = UNet_keras(img_shape=IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b35dca-1c17-48ca-8502-2e4666b23505",
   "metadata": {},
   "source": [
    "## TODO: Have not started on the below, simply copied and pasted . Need to clean them up toooooo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735a873-16b0-42c5-b656-c39b43dc6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy,BinaryCrossentropy \n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) #- dice_coef(in_gt, in_pred)\n",
    "\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "\n",
    "seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1f12c-72f6-4f6b-a6fc-30a57a62dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "step_count = min(MAX_TRAIN_STEPS, train_df_balanced.shape[0]//BATCH_SIZE)\n",
    "loss_history = [seg_model.fit(dataset, \n",
    "                             steps_per_epoch=step_count, \n",
    "                             epochs=NB_EPOCHS, \n",
    "                             validation_data=validation,\n",
    "                             callbacks=callbacks_list,\n",
    "                            workers=1 # the generator is not very thread safe\n",
    "                                       )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74843ae8-7a04-412f-8cd5-c7edd7b8ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_count = min(MAX_TRAIN_STEPS, train_df_balanced.shape[0]//BATCH_SIZE)\n",
    "loss_history = [seg_model.fit(dataset, \n",
    "                             steps_per_epoch=step_count, \n",
    "                             epochs=NB_EPOCHS, \n",
    "                             validation_data=validation,\n",
    "                             callbacks=callbacks_list,\n",
    "                            workers=1 # the generator is not very thread safe\n",
    "                                       )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5833597-aacf-45f3-ae3d-03af7dd7d990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
