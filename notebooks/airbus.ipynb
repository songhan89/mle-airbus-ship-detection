{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import gc; gc.enable() # memory is tight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage\n",
    "from typing import List\n",
    "from google.cloud import bigquery, storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "import tensorflow as tf\n",
    "from google_cloud_pipeline_components.experimental.custom_job import utils\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT: gs://mle_airbus_dataset/airbusmlepipeline/pipeline_root\n",
      "MODULE_ROOT: gs://mle_airbus_dataset/airbusmlepipeline/pipeline_module\n",
      "DATA_ROOT: gs://mle_airbus_dataset/airbusmlepipeline/data\n",
      "SERVING_MODEL_DIR: gs://mle_airbus_dataset/airbusmlepipeline/serving_model\n",
      "Project ID: mle-airbus-detection-smu\n",
      "Region: asia-east1\n",
      "Bucket name: mle_airbus_dataset\n",
      "Service Account: service-account-for-mle@mle-airbus-detection-smu.iam.gserviceaccount.com\n",
      "Vertex API Parent URI: projects/mle-airbus-detection-smu/locations/asia-east1\n",
      "gs://mle_airbus_dataset/train_v2/\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'mle-airbus-detection-smu' # Change to your project id.\n",
    "PROJECT_NUMBER = '484894607141'\n",
    "REGION = 'asia-east1' # Change to your region.\n",
    "BUCKET = 'mle_airbus_dataset' # Change to your bucket name.\n",
    "SERVICE_ACCOUNT = \"service-account-for-mle@mle-airbus-detection-smu.iam.gserviceaccount.com\"\n",
    "\n",
    "if PROJECT == \"\" or PROJECT is None or PROJECT == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT = shell_output[0]\n",
    "    \n",
    "if SERVICE_ACCOUNT == \"\" or SERVICE_ACCOUNT is None or SERVICE_ACCOUNT == \"[your-service-account]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.account)' 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"[your-bucket-name]\":\n",
    "    # Get your bucket name to GCP projet id\n",
    "    BUCKET = PROJECT\n",
    "    # Try to create the bucket if it doesn'exists\n",
    "    ! gsutil mb -l $REGION gs://$BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "!gcloud config set project {PROJECT}\n",
    "    \n",
    "    \n",
    "PARENT = f\"projects/{PROJECT}/locations/{REGION}\"\n",
    "\n",
    "PIPELINE_NAME = 'airbusmlepipeline'\n",
    "\n",
    "# Path to various pipeline artifact.\n",
    "PIPELINE_ROOT = 'gs://{}/{}/pipeline_root'.format(\n",
    "    BUCKET, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' Python module.\n",
    "MODULE_ROOT = 'gs://{}/{}/pipeline_module'.format(\n",
    "    BUCKET, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' data.\n",
    "DATA_ROOT = 'gs://{}/{}/data'.format(BUCKET, PIPELINE_NAME)\n",
    "\n",
    "# This is the path where your model will be pushed for serving.\n",
    "SERVING_MODEL_DIR = 'gs://{}/{}/serving_model'.format(\n",
    "    BUCKET, PIPELINE_NAME)\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))\n",
    "print('MODULE_ROOT: {}'.format(MODULE_ROOT))\n",
    "print('DATA_ROOT: {}'.format(DATA_ROOT))\n",
    "print('SERVING_MODEL_DIR: {}'.format(SERVING_MODEL_DIR))\n",
    "\n",
    "BQ_DATASET_NAME = 'mle-airbus-detection-smu.airbus_label_dataset' # Change to your BQ dataset name.\n",
    "BQ_TABLE_NAME = 'airbus_label'\n",
    "BQ_LOCATION = ' asia-east1'\n",
    "    \n",
    "print(\"Project ID:\", PROJECT)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)\n",
    "print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "print(\"Vertex API Parent URI:\", PARENT)\n",
    "\n",
    "! gsutil ls -al \"gs://\"$BUCKET\n",
    "\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT)\n",
    "bucket = storage_client.get_bucket(BUCKET)\n",
    "storage_path = f\"gs://{BUCKET}/train_v2/\"\n",
    "print (storage_path)\n",
    "\n",
    "VERSION = 'v01'\n",
    "DATASET_DISPLAY_NAME = 'airbus-ship-dataset-display'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "\n",
    "WORKSPACE = f'gs://{BUCKET}/{DATASET_DISPLAY_NAME}'\n",
    "EXPERIMENT_ARTIFACTS_DIR = os.path.join(WORKSPACE, 'experiments')\n",
    "\n",
    "TENSORBOARD_DISPLAY_NAME = f'tb-{DATASET_DISPLAY_NAME}'\n",
    "EXPERIMENT_NAME = f'{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 5\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 400\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 200\n",
    "AUGMENT_BRIGHTNESS = False\n",
    "N_SAMPLE = 10\n",
    "IMG_SHAPE = (768, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud auth list 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[2].strip()\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://mle_airbus_dataset/train_v2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No changes made to gs://mle_airbus_dataset/\n"
     ]
    }
   ],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator \"gs://\"$BUCKET\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer \"gs://\"$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Infra on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import aiplatform, bigquery\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "\n",
    "aiplatform.init(project=PROJECT, location=REGION, staging_bucket=BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest AcceleratorType.NVIDIA_TESLA_K80 1\n",
      "Deployment: us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-8:latest AcceleratorType.NVIDIA_TESLA_K80 1\n",
      "Train machine type n1-standard-4\n",
      "Deploy machine type n1-standard-4\n"
     ]
    }
   ],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (aip.AcceleratorType.NVIDIA_TESLA_K80, 1)\n",
    "\n",
    "DEPLOY_GPU, DEPLOY_NGPU = (aip.AcceleratorType.NVIDIA_TESLA_K80, 1)\n",
    "\n",
    "TRAIN_VERSION = \"tf-gpu.2-8\"\n",
    "DEPLOY_VERSION = \"tf2-gpu.2-8\"\n",
    "\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)\n",
    "\n",
    "MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"SELECT * FROM `mle-airbus-detection-smu.airbus_label_dataset.train`\"\n",
    "\n",
    "BQ_SOURCE_TRAIN = \"bq://mle-airbus-detection-smu.airbus_label_dataset.train\"\n",
    "BQ_SOURCE_TEST = \"bq://mle-airbus-detection-smu.airbus_label_dataset.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No changes made to gs://mle_airbus_dataset/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ImageId                                      EncodedPixels  ships  \\\n",
      "0  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...      1   \n",
      "1  00031f145.jpg  340363 1 341129 4 341896 6 342663 7 343429 10 ...      1   \n",
      "2  000d42241.jpg  369226 3 369992 5 370760 5 371528 5 372296 5 3...      1   \n",
      "3  000e6378b.jpg  224667 2 225431 6 226196 10 226962 12 227730 1...      1   \n",
      "4  001234638.jpg  131064 1 131831 3 132599 5 133366 7 134133 9 1...      1   \n",
      "\n",
      "   has_ship  \n",
      "0       1.0  \n",
      "1       1.0  \n",
      "2       1.0  \n",
      "3       1.0  \n",
      "4       1.0  \n"
     ]
    }
   ],
   "source": [
    "bqclient = bigquery.Client()\n",
    "\n",
    "# Download a table.\n",
    "table = bigquery.TableReference.from_string(\n",
    "    \"mle-airbus-detection-smu.airbus_label_dataset.train\"\n",
    ")\n",
    "rows = bqclient.list_rows(\n",
    "    table\n",
    ")\n",
    "dataframe = rows.to_dataframe(\n",
    "    # Optionally, explicitly request to use the BigQuery Storage API. As of\n",
    "    # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n",
    "    # API is used by default.\n",
    "    create_bqstorage_client=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00031f145.jpg</td>\n",
       "      <td>340363 1 341129 4 341896 6 342663 7 343429 10 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d42241.jpg</td>\n",
       "      <td>369226 3 369992 5 370760 5 371528 5 372296 5 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e6378b.jpg</td>\n",
       "      <td>224667 2 225431 6 226196 10 226962 12 227730 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001234638.jpg</td>\n",
       "      <td>131064 1 131831 3 132599 5 133366 7 134133 9 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148299</th>\n",
       "      <td>ff7ac7f3c.jpg</td>\n",
       "      <td>452546 1 453313 3 454079 5 454846 7 455613 9 4...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148300</th>\n",
       "      <td>ff7ac7f3c.jpg</td>\n",
       "      <td>73142 1 73909 4 74676 6 75443 8 76212 9 76981 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148301</th>\n",
       "      <td>ff7ac7f3c.jpg</td>\n",
       "      <td>357792 2 358558 4 359324 7 360092 7 360861 6 3...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148302</th>\n",
       "      <td>ff7ac7f3c.jpg</td>\n",
       "      <td>327886 1 328652 4 329419 6 330188 5 330957 5 3...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148303</th>\n",
       "      <td>ff7ac7f3c.jpg</td>\n",
       "      <td>361459 2 362224 5 362989 9 363754 12 364520 15...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148304 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId                                      EncodedPixels  \\\n",
       "0       000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...   \n",
       "1       00031f145.jpg  340363 1 341129 4 341896 6 342663 7 343429 10 ...   \n",
       "2       000d42241.jpg  369226 3 369992 5 370760 5 371528 5 372296 5 3...   \n",
       "3       000e6378b.jpg  224667 2 225431 6 226196 10 226962 12 227730 1...   \n",
       "4       001234638.jpg  131064 1 131831 3 132599 5 133366 7 134133 9 1...   \n",
       "...               ...                                                ...   \n",
       "148299  ff7ac7f3c.jpg  452546 1 453313 3 454079 5 454846 7 455613 9 4...   \n",
       "148300  ff7ac7f3c.jpg  73142 1 73909 4 74676 6 75443 8 76212 9 76981 ...   \n",
       "148301  ff7ac7f3c.jpg  357792 2 358558 4 359324 7 360092 7 360861 6 3...   \n",
       "148302  ff7ac7f3c.jpg  327886 1 328652 4 329419 6 330188 5 330957 5 3...   \n",
       "148303  ff7ac7f3c.jpg  361459 2 362224 5 362989 9 363754 12 364520 15...   \n",
       "\n",
       "        ships  has_ship  \n",
       "0           1       1.0  \n",
       "1           1       1.0  \n",
       "2           1       1.0  \n",
       "3           1       1.0  \n",
       "4           1       1.0  \n",
       "...       ...       ...  \n",
       "148299     15       1.0  \n",
       "148300     15       1.0  \n",
       "148301     15       1.0  \n",
       "148302     15       1.0  \n",
       "148303     15       1.0  \n",
       "\n",
       "[148304 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
