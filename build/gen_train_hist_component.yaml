name: Gen train hist component
inputs:
- {name: project_dict, type: JsonObject}
outputs:
- {name: train_hist_fpath, type: String}
- {name: train_threshold_fpath, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-storage' 'opencv-python-headless' 'pandas' 'pyarrow' 'fsspec' 'gcsfs' 'kfp==1.8.12' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def gen_train_hist_component(
          project_dict: dict
          ) -> NamedTuple(
          "Outputs",
          [
              ("train_hist_fpath", str),  # Return path to histogram of training data.
              ("train_threshold_fpath", str),  # Return path to threshold value.
          ],
          ):

          import cv2
          import urllib
          import numpy as np
          import pandas as pd
          from google.cloud import storage


          PROJECT_ID = project_dict['PROJECT_ID']
          GCS_BUCKET = project_dict['GCS_BUCKET']
          GCS_TRAIN_IMAGES=f"gs://{GCS_BUCKET}/train_v2/"

          # read the parquet files
          train_data = pd.read_parquet(f"gs://{GCS_BUCKET}/train.parquet")
          test_data = pd.read_parquet(f"gs://{GCS_BUCKET}/test.parquet")

          # load training images to calculate histogram
          gcs_url = f"https://storage.googleapis.com/{GCS_TRAIN_IMAGES.replace('gs://','')}"

          train_images = []
          test_images = []

          for image_id in train_data['ImageId']:
              resp = urllib.request.urlopen(f'{gcs_url}{image_id}')
              image = np.asarray(bytearray(resp.read()), dtype="uint8")
              image = cv2.imdecode(image, cv2.IMREAD_COLOR)
              train_images.append(image)

          for image_id in test_data['ImageId']:
              resp = urllib.request.urlopen(f'{gcs_url}{image_id}')
              image = np.asarray(bytearray(resp.read()), dtype="uint8")
              image = cv2.imdecode(image, cv2.IMREAD_COLOR)
              test_images.append(image)

          channels = [0, 1, 2]
          hist_size = [256] * 3
          hist_ranges = [0, 256] * 3

          # compute the image histograms for training data
          train_hist = cv2.calcHist(train_images,
                                    channels,
                                    None,
                                    hist_size,
                                    hist_ranges,
                                    accumulate = True)
          cv2.normalize(train_hist, train_hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)

          # compute the image histograms for training data
          test_hist = cv2.calcHist(test_images,
                                   channels,
                                   None,
                                   hist_size,
                                   hist_ranges,
                                   accumulate = True)
          cv2.normalize(test_hist, test_hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)

          # use correlation method for comparison
          threshold = cv2.compareHist(train_hist, test_hist, 0)

          # reshaping the array from 3D matrice to 2D matrice.
          arrReshaped = train_hist.reshape(train_hist.shape[0], -1)
          # saving reshaped array to file.
          np.savetxt('train_hist.csv', arrReshaped)

          with open('train_threshold.txt','w') as f:
              f.write(f'{threshold}')

          # move the files to GCS
          bucket = storage.Client().bucket(GCS_BUCKET)

          blob = bucket.blob('train_hist.csv')
          blob.upload_from_filename('train_hist.csv')
          blob = bucket.blob('train_threshold.txt')
          blob.upload_from_filename('train_threshold.txt')

          return f"gs://{GCS_BUCKET}/train_hist.csv", f"gs://{GCS_BUCKET}/train_threshold.txt"

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - gen_train_hist_component
